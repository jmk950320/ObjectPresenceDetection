import os
import sys
import torch
import numpy as np
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
from torchvision import transforms
import yaml
# feature_visualizetion ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ ì„í¬íŠ¸ ê°€ëŠ¥í•˜ê²Œ í•¨
sys.path.insert(0, str(Path(__file__).parent.parent / "feature_visualizetion"))
from vis_resnet import create_model, extract_features_like_original

def load_config(config_path):
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    return config

def get_roi_coords(roi, roi_format, h_img, w_img):
    """
    ROIë¥¼ (x1, y1, x2, y2) ì •ìˆ˜ ì¢Œí‘œë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    """
    if not roi:
        return 0, 0, w_img, h_img
    if roi_format == 'xyxy':
        x1, y1, x2, y2 = roi
    elif roi_format == 'xywh':
        x1, y1, w_roi, h_roi = roi
        x2, y2 = x1 + w_roi, y1 + h_roi
    else:
        return 0, 0, w_img, h_img

    x1, y1 = max(0, int(x1)), max(0, int(y1))
    x2, y2 = min(w_img, int(x2)), min(h_img, int(y2))
    return x1, y1, x2, y2

def apply_mask_and_roi(grid_h, grid_w, mask_path, roi, roi_format, original_size=None):
    """
    Apply mask and ROI to the feature map grid.
    Returns a boolean mask of shape (grid_h, grid_w)
    """
    H, W = grid_h, grid_w
    valid_mask = np.ones((H, W), dtype=bool)
    
    if (mask_path and os.path.exists(mask_path)) or roi:
        if mask_path and os.path.exists(mask_path):
            mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        else:
            # If no mask image but ROI exists, create a white mask if original_size is known
            if roi and original_size:
                oh, ow = original_size
                mask_img = np.full((oh, ow), 255, dtype=np.uint8)
            else:
                mask_img = None

        if mask_img is not None:
            if roi:
                h_img, w_img = mask_img.shape[:2]
                x1, y1, x2, y2 = get_roi_coords(roi, roi_format, h_img, w_img)
                mask_img = mask_img[y1:y2, x1:x2]

            if mask_img.size > 0:
                mask_resized = cv2.resize(mask_img, (W, H), interpolation=cv2.INTER_NEAREST)
                valid_mask = valid_mask & (mask_resized > 127)
            else:
                valid_mask[:] = False
            
    return valid_mask

def load_pca_params(pca_path):
    """
    PCA componentsì™€ meanì„ ë¡œë“œí•¨
    """
    data = np.load(pca_path)
    components = data['pca_components'] # (n_components, dim)
    mean = data['pca_mean']             # (dim,)
    print(f"âœ… PCA íŒŒë¼ë¯¸í„° ë¡œë“œë¨: components {components.shape}, mean {mean.shape}")
    return components, mean

def apply_pca_manual(features, components, mean):
    """
    ìˆ˜ë™ìœ¼ë¡œ PCA ë³€í™˜ ìˆ˜í–‰: (features - mean) @ components.T
    features: (N, dim) numpy array ë˜ëŠ” torch.Tensor
    """
    if torch.is_tensor(features):
        features = features.cpu().numpy()
    
    # ì •ê·œí™” (mean subtraction)
    centered_features = features - mean
    
    # íˆ¬ì˜ (dot product with components)
    projected = np.dot(centered_features, components.T)
    
    return projected

def visualize_projected_features(projected, h, w, original_image=None, save_path=None, valid_mask=None):
    """
    PCA íˆ¬ì˜ëœ íŠ¹ì§•ì„ ì‹œê°í™” (RGB ë§¤í•‘)
    projected: (N, 3) 
    """
    n_components = projected.shape[1]
    
    # ì‹œê°í™”ë¥¼ ìœ„í•´ [0, 1] ë²”ìœ„ë¥¼ ë§ì¶¤ (Min-Max ë˜ëŠ” Sigmoid)
    # If valid_mask is provided, calculate min/max only from valid regions
    if valid_mask is not None:
        flat_mask = valid_mask.flatten()
        if np.any(flat_mask):
            p_min = projected[flat_mask].min(axis=0)
            p_max = projected[flat_mask].max(axis=0)
        else:
            p_min = projected.min(axis=0)
            p_max = projected.max(axis=0)
    else:
        p_min = projected.min(axis=0)
        p_max = projected.max(axis=0)

    normalized = (projected - p_min) / (p_max - p_min + 1e-8)
    
    # (H, W, C) í˜•íƒœë¡œ ë³€í™˜
    if n_components >= 3:
        vis_img = normalized[:, :3].reshape(h, w, 3)
    elif n_components == 2:
        vis_img = np.zeros((h, w, 3))
        vis_img[:, :, :2] = normalized.reshape(h, w, 2)
    else: # 1
        vis_img = normalized.reshape(h, w)
        cmap = plt.get_cmap('jet')
        vis_img = cmap(vis_img)[:, :, :3]
    
    # Apply valid mask
    if valid_mask is not None:
        vis_img = vis_img * valid_mask[:, :, np.newaxis]

    # Apply interpolation
    vis_img_up = cv2.resize(vis_img, (224, 224), interpolation=cv2.INTER_LINEAR)

    plt.figure(figsize=(10, 5))
    
    if original_image is not None:
        plt.subplot(1, 2, 1)
        if torch.is_tensor(original_image):
            img_np = original_image.permute(1, 2, 0).cpu().numpy()
            # Denormalize
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            img_np = std * img_np + mean
            img_np = np.clip(img_np, 0, 1)
            plt.imshow(img_np)
        else:
            plt.imshow(original_image)
        plt.title("Original Image")
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
    
    # Upsample for better view
    vis_img_up = cv2.resize(vis_img, (224, 224), interpolation=cv2.INTER_LINEAR)
    plt.imshow(vis_img_up)
    plt.title(f"Manual PCA Visualization ({n_components} components)")
    plt.axis('off')
    
    if save_path:
        plt.savefig(save_path, bbox_inches='tight', dpi=300)
        print(f"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥ë¨: {save_path}")
    
    plt.show()
    plt.close()

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def render_pca_visualization(projected, h, w, original_image_tensor=None, valid_mask=None):
    """
    PCA íˆ¬ì˜ëœ íŠ¹ì§•ì„ ì‹œê°í™”í•˜ì—¬ numpy array(BGR)ë¡œ ë°˜í™˜ (ë¹„ë””ì˜¤ í”„ë ˆì„ìš©)
    """
    n_components = projected.shape[1]
        
    normalized = sigmoid(projected * 2)
    
    # (H, W, C) array creation
    if n_components >= 3:
        vis_img = normalized[:, :3].reshape(h, w, 3)
    elif n_components == 2:
        vis_img = np.zeros((h, w, 3), dtype=np.float32)
        vis_img[:, :, :2] = normalized.reshape(h, w, 2)
    else: # 1
        vis_img = normalized.reshape(h, w)
        cmap = plt.get_cmap('jet')
        vis_img = cmap(vis_img)[:, :, :3]
    
    # Apply valid mask (zero out invalid regions)
    if valid_mask is not None:
        vis_img = vis_img * valid_mask[:, :, np.newaxis]

    # Resize PCA visualization to 224x224
    vis_img_up = cv2.resize(vis_img, (224, 224), interpolation=cv2.INTER_LINEAR)
    vis_img_bgr = cv2.cvtColor((vis_img_up * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)

    if original_image_tensor is not None:
        # Denormalize and convert original_image_tensor to BGR
        img_np = original_image_tensor.permute(1, 2, 0).cpu().numpy()
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        img_np = std * img_np + mean
        img_np = np.clip(img_np, 0, 1)
        img_bgr = cv2.cvtColor((img_np * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)
        
        # Concatenate side-by-side
        combined = np.hstack((img_bgr, vis_img_bgr))
        return combined
    
    return vis_img_bgr

def process_video(video_path, model, device, components, pca_mean, args, output_path=None):
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì— ëŒ€í•´ í”„ë ˆì„ë³„ íŠ¹ì§• ì¶”ì¶œ, PCA ë³€í™˜, ì‹œê°í™” ìˆ˜í–‰ ë° ë¹„ë””ì˜¤ ì €ì¥
    """
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # Output size is (448, 224) because we stack (224, 224) horizontal
    out = None
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (448, 224))

    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    print(f"ğŸ¥ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘: {video_path} ({total_frames} frames)")
    
    # ROI ì ìš© ì¢Œí‘œ ê³„ì‚°
    x1, y1, x2, y2 = get_roi_coords(args.roi, args.roi_format, orig_h, orig_w)
    
    # Pre-calculate valid_mask
    ret, first_frame = cap.read()
    if not ret:
        print("âŒ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        cap.release()
        return
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    
    # ROI Crop
    first_frame_cropped = first_frame[y1:y2, x1:x2]
    img_rgb = cv2.cvtColor(first_frame_cropped, cv2.COLOR_BGR2RGB)
    img_tensor = transform(img_rgb)
    with torch.inference_mode():
        _, h_grid, w_grid = extract_features_like_original(
            img_tensor, 
            model_name=args.model, 
            n_layers=[args.layer], 
            device=device, 
            model=model
        )
    valid_mask = apply_mask_and_roi(h_grid, w_grid, args.mask, args.roi, args.roi_format, original_size=(orig_h, orig_w))
    
    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
            
        # ROI Crop
        frame_cropped = frame[y1:y2, x1:x2]
        img_rgb = cv2.cvtColor(frame_cropped, cv2.COLOR_BGR2RGB)
        img_tensor = transform(img_rgb)
        
        # íŠ¹ì§• ì¶”ì¶œ
        with torch.inference_mode():
            features, h, w = extract_features_like_original(
                img_tensor, 
                model_name=args.model, 
                n_layers=[args.layer], 
                device=device, 
                model=model
            )
        
        # PCA ë³€í™˜
        projected = apply_pca_manual(features, components, pca_mean)
        
        # ì‹œê°í™” ë Œë”ë§ (valid_mask ì ìš©)
        combined_frame = render_pca_visualization(projected, h, w, img_tensor, valid_mask=valid_mask)
        
        if out:
            out.write(combined_frame)
            
        frame_idx += 1
        if frame_idx % 10 == 0:
            print(f"Processed {frame_idx}/{total_frames} frames...")
            
    cap.release()
    if out:
        out.release()
    print(f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {output_path}")

def process_single_image(image_path, model, device, components, pca_mean, args, output_path=None):
    """
    ì´ë¯¸ì§€ í•˜ë‚˜ì— ëŒ€í•´ íŠ¹ì§• ì¶”ì¶œ, PCA ë³€í™˜, ì‹œê°í™” ìˆ˜í–‰
    """
    img = cv2.imread(str(image_path))
    if img is None:
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return
    # ROI ì ìš© ì¢Œí‘œ ê³„ì‚°
    x1, y1, x2, y2 = get_roi_coords(args.roi, args.roi_format, orig_h, orig_w)
    
    # ROI Crop
    img_cropped = img[y1:y2, x1:x2]
    img_rgb = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2RGB)
    img_tensor = transform(img_rgb)
    
    # íŠ¹ì§• ì¶”ì¶œ
    features, h, w = extract_features_like_original(
        img_tensor, 
        model_name=args.model, 
        n_layers=[args.layer], 
        device=device, 
        model=model
    )
    
    # PCA ë³€í™˜
    projected = apply_pca_manual(features, components, pca_mean)
    
    # ROI ë° Mask ì ìš©
    valid_mask = apply_mask_and_roi(h, w, args.mask, args.roi, args.roi_format, original_size=(orig_h, orig_w))
    
    # ì‹œê°í™” ë° ì €ì¥
    # visualize_projected_featuresëŠ” matplotlib ê¸°ë°˜ì´ë¼ valid_mask ì ìš©ì„ ìœ„í•´ ìˆ˜ì •ì´ í•„ìš”í•˜ê±°ë‚˜
    # projectedë¥¼ ë¯¸ë¦¬ í•„í„°ë§í•´ì•¼ í•¨. ì—¬ê¸°ì„œëŠ” projectedë¥¼ í•„í„°ë§í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ëŒ€ì‘.
    
    # projected: (N, C)
    if valid_mask is not None:
        flat_mask = valid_mask.flatten()
        # ì‹œê°í™”ë¥¼ ìœ„í•´ ë§ˆìŠ¤í¬ ë°–ì€ 0 (ë˜ëŠ” minê°’)ìœ¼ë¡œ ì²˜ë¦¬
        # visualize_projected_features ë‚´ì—ì„œ min-maxë¥¼ í•˜ë¯€ë¡œ, 
        # ë§ˆìŠ¤í¬ ë°–ì„ p_minìœ¼ë¡œ ì±„ìš°ë©´ ì‹œê°í™”ì—ì„œ ê²€ê²Œ ë‚˜ì˜´.
        # í•˜ì§€ë§Œ visualize_projected_features ë‚´ë¶€ ë¡œì§ì„ ë°”ê¾¸ëŠ”ê²Œ ê¹”ë”í•¨.
        pass

    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ render_pca_visualizationì„ ì‚¬ìš©í•˜ì—¬ ì €ì¥í•  ìˆ˜ë„ ìˆìŒ.
    # ë§Œì•½ matplotlib ê¸°ë°˜ visualize_projected_featuresë¥¼ ìœ ì§€í•˜ê³  ì‹¶ë‹¤ë©´ í•´ë‹¹ í•¨ìˆ˜ë„ ìˆ˜ì • í•„ìš”.
    # ì¼ë‹¨ì€ render_pca_visualization ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµì²´í•˜ê±°ë‚˜ ìˆ˜ì • ì œì•ˆ.
    
    # visualize_projected_features ë‚´ë¶€ì—ì„œ valid_maskë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •í•˜ëŠ” ê²ƒì´ ì¢‹ê² ìŒ.
    visualize_projected_features(projected, h, w, img_tensor, output_path, valid_mask=valid_mask)

def main():
    import argparse
    parser = argparse.ArgumentParser(description='PCA íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•œ íŠ¹ì§• ì¶”ì¶œ ë° ì‹œê°í™” í…ŒìŠ¤íŠ¸')
    parser.add_argument('--config', type=str, help='ì„¤ì • íŒŒì¼ ê²½ë¡œ (YAML)')
    args = parser.parse_args()

    # ì„¤ì • íŒŒì¼ ë¡œë“œ
    config = {}
    if args.config and os.path.exists(args.config):
        config = load_config(args.config)
        print(f"ğŸ“„ ì„¤ì • íŒŒì¼ ë¡œë“œë¨: {args.config}")

    # ì¸ì ë³‘í•© (CLIê°€ ìš°ì„ )
    args.image = config.get('image') or config.get('video') # video í‚¤ë„ ì§€ì›
    args.pca = config.get('pca', '/home/kjm/foreground_segmentation/sampling_result/aggregated_sampled_pca.npz')
    args.model = config.get('model', 'resnet50')
    args.layer = config.get('layer_indices', config.get('layer', 2)) # Support both names
    args.roi = config.get('roi')
    args.roi_format =  config.get('roi_format', 'xyxy')
    args.mask = config.get('mask', None)
    args.output = config.get('output', 'pca_test_result.mp4' if 'video' in config or (args.image and Path(args.image).suffix.lower() in ('.mp4', '.avi', '.mov', '.mkv')) else 'pca_test_result.png')

    if not args.image:
        print("âŒ ì…ë ¥ ì´ë¯¸ì§€(ë˜ëŠ” í´ë”) ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # 1. PCA íŒŒë¼ë¯¸í„° ë¡œë“œ
    if not os.path.exists(args.pca):
        print(f"âŒ PCA íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.pca}")
        return
    components, pca_mean = load_pca_params(args.pca)
    
    # 2. ëª¨ë¸ ë¡œë“œ
    print(f"ğŸš€ ëª¨ë¸({args.model}) ë¡œë“œ ì¤‘...")
    model = create_model(args.model, pretrained=True, device=device)
    
    # 3. ì…ë ¥ ì²˜ë¦¬ (íŒŒì¼ vs í´ë”)
    input_path = Path(args.image)
    video_extensions = ('.mp4', '.avi', '.mov', '.mkv')
    
    if input_path.is_dir():
        # í´ë” ë‚´ ì´ë¯¸ì§€ ê²€ìƒ‰
        image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')
        image_files = sorted([f for f in input_path.iterdir() if f.suffix.lower() in image_extensions])
        
        if not image_files:
            print(f"âŒ í´ë” ë‚´ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {args.image}")
            return
            
        # ì¶œë ¥ í´ë” ìƒì„±
        output_dir = Path(args.output)
        if output_dir.suffix: # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš° ë¶€ëª¨ ë””ë ‰í† ë¦¬ì— í´ë” ìƒì„±
            output_dir = output_dir.parent / "pca_results"
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“‚ í´ë” ì²˜ë¦¬ ì‹œì‘: {len(image_files)}ê°œ ì´ë¯¸ì§€, ì €ì¥: {output_dir}")
        
        for i, img_path in enumerate(image_files):
            out_path = output_dir / f"{img_path.stem}_pca.png"
            process_single_image(img_path, model, device, components, pca_mean, args, out_path)
            if (i + 1) % 10 == 0:
                print(f"Processed {i + 1}/{len(image_files)} images...")
    elif input_path.suffix.lower() in video_extensions:
        # ë¹„ë””ì˜¤ ì²˜ë¦¬
        process_video(input_path, model, device, components, pca_mean, args, args.output)
    else:
        # ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
        process_single_image(input_path, model, device, components, pca_mean, args, args.output)

if __name__ == "__main__":
    main()
